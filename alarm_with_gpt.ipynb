{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "lNtbvyp7O5E6",
        "outputId": "3faecf3b-2b77-4296-8433-27c75d815cc2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a27fc1d-cfad-4703-945e-d3aea2a8682e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9a27fc1d-cfad-4703-945e-d3aea2a8682e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving combine.xlsx to combine.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6fa8da47-d6a8-4e02-b7cf-c73a390d99d2\", \"alarm_analysis_results.json\", 230047)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import json\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Custom JSON encoder\n",
        "class CustomJSONEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, (np.integer)):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, (np.floating)):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, (datetime, pd.Timestamp)):\n",
        "            return obj.isoformat()\n",
        "        return super().default(obj)\n",
        "\n",
        "# Upload and read file\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(filename, header=3)\n",
        "\n",
        "# Data cleaning\n",
        "df['EVENT DAY'] = pd.to_datetime(df['EVENT DAY'], errors='coerce')\n",
        "df['RESOLVED TIME'] = pd.to_datetime(df['RESOLVED TIME'], errors='coerce')\n",
        "df['CLIENT NAME'] = df['CLIENT NAME'].replace({'americanauae': 'UAE', 'americanaksa': 'KSA'})\n",
        "df['SOURCE NAME'] = df['SOURCE NAME'].str.strip()\n",
        "\n",
        "# Calculate resolution time in minutes\n",
        "df['resolution_minutes'] = (df['RESOLVED TIME'] - df['EVENT DAY']).dt.total_seconds() / 60\n",
        "valid_resolutions = df.dropna(subset=['RESOLVED TIME'])\n",
        "valid_resolutions = valid_resolutions[valid_resolutions['RESOLVED TIME'] >= valid_resolutions['EVENT DAY']]\n",
        "\n",
        "# Initialize analysis results\n",
        "analysis_results = {}\n",
        "\n",
        "# 1-4. Basic alarm distributions\n",
        "analysis_results['alarm_by_client'] = df['CLIENT NAME'].value_counts().to_dict()\n",
        "if 'SOURCE TYPE NAME' in df.columns:\n",
        "    analysis_results['alarm_by_source_type'] = df['SOURCE TYPE NAME'].value_counts().to_dict()\n",
        "if 'GROUP' in df.columns:\n",
        "    analysis_results['alarm_by_group'] = df['GROUP'].value_counts().to_dict()\n",
        "analysis_results['alarm_by_name'] = df['NAME'].value_counts().to_dict()\n",
        "\n",
        "# 5. Weekly and monthly trends with PATH\n",
        "if 'SOURCE NAME' in df.columns and 'PATH' in df.columns:\n",
        "    source_path_mapping = df.groupby('SOURCE NAME')['PATH'].agg(lambda x: x.mode()[0]).to_dict()\n",
        "\n",
        "    # Weekly analysis\n",
        "    weekly = (df.groupby(['SOURCE NAME', df['EVENT DAY'].dt.isocalendar().week.astype(str)])\n",
        "              .size().unstack(fill_value=0))\n",
        "    weekly = weekly.loc[(weekly > 0).any(axis=1)]\n",
        "    weekly_dict = {}\n",
        "    for source, week_data in weekly.to_dict('index').items():\n",
        "        weekly_dict[source] = {\n",
        "            'path': source_path_mapping.get(source, 'N/A'),\n",
        "            'counts': {week: count for week, count in week_data.items() if count > 0}\n",
        "        }\n",
        "    analysis_results['alarm_by_source_weekly'] = weekly_dict\n",
        "\n",
        "    # Monthly analysis\n",
        "    monthly = (df.groupby(['SOURCE NAME', df['EVENT DAY'].dt.month_name().astype(str)])\n",
        "               .size().unstack(fill_value=0))\n",
        "    monthly = monthly.loc[(monthly > 0).any(axis=1)]\n",
        "    monthly_dict = {}\n",
        "    for source, month_data in monthly.to_dict('index').items():\n",
        "        monthly_dict[source] = {\n",
        "            'path': source_path_mapping.get(source, 'N/A'),\n",
        "            'counts': {month: count for month, count in month_data.items() if count > 0}\n",
        "        }\n",
        "    analysis_results['alarm_by_source_monthly'] = monthly_dict\n",
        "\n",
        "# 6. Hourly distribution\n",
        "df['hour'] = df['EVENT DAY'].dt.hour.astype(str)\n",
        "analysis_results['alarm_by_hour'] = df['hour'].value_counts().sort_index().to_dict()\n",
        "\n",
        "# 7. Top/Bottom 20 sources with PATH\n",
        "if 'SOURCE NAME' in df.columns and 'PATH' in df.columns:\n",
        "    source_counts = df['SOURCE NAME'].value_counts()\n",
        "    analysis_results['top20_sources'] = {\n",
        "        source: {\n",
        "            'count': int(count),\n",
        "            'path': source_path_mapping.get(source, 'N/A')\n",
        "        } for source, count in source_counts.head(20).items()\n",
        "    }\n",
        "    analysis_results['bottom20_sources'] = {\n",
        "        source: {\n",
        "            'count': int(count),\n",
        "            'path': source_path_mapping.get(source, 'N/A')\n",
        "        } for source, count in source_counts.tail(20).items()\n",
        "    }\n",
        "\n",
        "# 8. Resolution time stats\n",
        "analysis_results['resolution_time_stats'] = valid_resolutions.groupby('NAME')['resolution_minutes'].agg(\n",
        "    ['mean', 'median', 'count']).round(2).to_dict('index')\n",
        "\n",
        "# 9. Highest and Lowest 20 resolution times with PATH\n",
        "if 'SOURCE NAME' in df.columns and 'PATH' in df.columns:\n",
        "    # Get top 20 longest resolutions\n",
        "    top20_longest = valid_resolutions.nlargest(20, 'resolution_minutes')[['SOURCE NAME', 'PATH', 'resolution_minutes', 'EVENT DAY', 'RESOLVED TIME']]\n",
        "    analysis_results['top20_longest_resolutions'] = [\n",
        "        {\n",
        "            'source': row['SOURCE NAME'],\n",
        "            'path': row['PATH'],\n",
        "            'time_minutes': round(row['resolution_minutes'], 2),\n",
        "            'event_day': row['EVENT DAY'].isoformat(),\n",
        "            'resolved_time': row['RESOLVED TIME'].isoformat()\n",
        "        } for _, row in top20_longest.iterrows()\n",
        "    ]\n",
        "\n",
        "    # Get top 20 fastest resolutions\n",
        "    top20_fastest = valid_resolutions.nsmallest(20, 'resolution_minutes')[['SOURCE NAME', 'PATH', 'resolution_minutes', 'EVENT DAY', 'RESOLVED TIME']]\n",
        "    analysis_results['top20_fastest_resolutions'] = [\n",
        "        {\n",
        "            'source': row['SOURCE NAME'],\n",
        "            'path': row['PATH'],\n",
        "            'time_minutes': round(row['resolution_minutes'], 2),\n",
        "            'event_day': row['EVENT DAY'].isoformat(),\n",
        "            'resolved_time': row['RESOLVED TIME'].isoformat()\n",
        "        } for _, row in top20_fastest.iterrows()\n",
        "    ]\n",
        "\n",
        "# Reorganize results with resolution extremes before temporal trends\n",
        "final_results = {\n",
        "    \"summary\": {\n",
        "        \"total_alarms\": len(df),\n",
        "        \"resolved_alarms\": len(valid_resolutions),\n",
        "        \"resolution_rate in Percentage\": str(round(len(valid_resolutions)/len(df)*100, 2)) + \"%\",\n",
        "        \"time_period\": {\n",
        "            \"start\": df['EVENT DAY'].min().isoformat(),\n",
        "            \"end\": df['EVENT DAY'].max().isoformat()\n",
        "        }\n",
        "    },\n",
        "    \"distributions\": {\n",
        "        \"by_client\": analysis_results['alarm_by_client'],\n",
        "        \"by_type\": analysis_results.get('alarm_by_source_type', {}),\n",
        "        \"by_group\": analysis_results.get('alarm_by_group', {}),\n",
        "        \"by_name\": analysis_results['alarm_by_name'],\n",
        "        \"by_hour\": analysis_results['alarm_by_hour']\n",
        "    },\n",
        "    \"source_analysis\": {\n",
        "        \"top_20\": analysis_results.get('top20_sources', {}),\n",
        "        \"bottom_20\": analysis_results.get('bottom20_sources', {})\n",
        "    },\n",
        "    \"performance\": {\n",
        "        \"resolution_times\": analysis_results['resolution_time_stats'],\n",
        "        \"sla_compliance/Resolved within the time limit\": {\n",
        "            \"within_15min\": round((valid_resolutions['resolution_minutes'] <= 15).mean()*100, 2),\n",
        "            \"within_30min\": round((valid_resolutions['resolution_minutes'] <= 30).mean()*100, 2),\n",
        "            \"within_1hour\": round((valid_resolutions['resolution_minutes'] <= 60).mean()*100, 2)\n",
        "        }\n",
        "    },\n",
        "    \"resolution_extremes\": {\n",
        "        \"longest_20_resolutions\": analysis_results.get('top20_longest_resolutions', []),\n",
        "        \"fastest_20_resolutions\": analysis_results.get('top20_fastest_resolutions', [])\n",
        "    },\n",
        "    \"temporal_trends\": {\n",
        "        \"weekly\": analysis_results.get('alarm_by_source_weekly', {}),\n",
        "        \"monthly\": analysis_results.get('alarm_by_source_monthly', {})\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save final organized results\n",
        "with open('alarm_analysis_results.json', 'w') as f:\n",
        "    json.dump(final_results, f, indent=2, cls=CustomJSONEncoder)\n",
        "\n",
        "files.download('alarm_analysis_results.json')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install transformers -q\n",
        "\n",
        "import json\n",
        "from google.colab import files\n",
        "from transformers import pipeline\n",
        "from datetime import datetime\n",
        "\n",
        "# Sample JSON data\n",
        "sample_json = '''\n",
        "{\n",
        "  \"summary\": {\n",
        "    \"total_alarms\": 10380,\n",
        "    \"resolved_alarms\": 9999,\n",
        "    \"resolution_rate in Percentage\": \"96.33%\",\n",
        "    \"time_period\": {\n",
        "      \"start\": \"2025-05-01T20:00:34\",\n",
        "      \"end\": \"2025-05-12T03:11:35\"\n",
        "    }\n",
        "  },\n",
        "  \"distributions\": {\n",
        "    \"by_client\": {\n",
        "      \"KSA\": 5701,\n",
        "      \"UAE\": 4672,\n",
        "      \"Bahrain\": 7\n",
        "    },\n",
        "    \"by_type\": {\n",
        "      \"Freezer\": 5400,\n",
        "      \"Chiller\": 4713,\n",
        "      \"LV Panel Meter\": 183,\n",
        "      \"Commercial Tower\": 67,\n",
        "      \"Thermostat\": 16,\n",
        "      \"Sub Community\": 1\n",
        "    },\n",
        "    \"by_group\": {\n",
        "      \"ENVIRONMENTAL\": 10129,\n",
        "      \"ELECTRICAL\": 183,\n",
        "      \"PREVENTIVE\": 68\n",
        "    },\n",
        "    \"by_name\": {\n",
        "      \"Door Open\": 4714,\n",
        "      \"Extremely High Temperature\": 2251,\n",
        "      \"High Temperature\": 2201,\n",
        "      \"Low Temperature\": 963,\n",
        "      \"No power\": 183,\n",
        "      \"Site Not Communicating\": 68\n",
        "    }\n",
        "  },\n",
        "  \"source_analysis\": {\n",
        "    \"top_20\": {\n",
        "      \"T 118709 CH 02\": {\n",
        "        \"count\": 77,\n",
        "        \"path\": \"UAE/Dubai/TGIF Jumeirah - 118709\"\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "  \"performance\": {\n",
        "    \"resolution_times\": {\n",
        "      \"Door Open\": {\n",
        "        \"mean\": 50.42,\n",
        "        \"median\": 14.68,\n",
        "        \"count\": 4561\n",
        "      }\n",
        "    },\n",
        "    \"sla_compliance/Resolved within the time limit\": {\n",
        "      \"within_15min\": 42.89,\n",
        "      \"within_30min\": 59.09,\n",
        "      \"within_1hour\": 73.33\n",
        "    }\n",
        "  },\n",
        "  \"temporal_trends\": {\n",
        "    \"weekly\": {\n",
        "      \"T 118709 CH 02\": {\n",
        "        \"path\": \"UAE/Dubai/TGIF Jumeirah - 118709\",\n",
        "        \"counts\": {\n",
        "          \"19\": 77\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "'''\n",
        "\n",
        "def parse_json_to_text(json_data, filename=\"Unknown\"):\n",
        "    \"\"\"Convert JSON to concise text for the chatbot.\"\"\"\n",
        "    try:\n",
        "        data = json.loads(json_data)\n",
        "        text = f\"Data from {filename}:\\n\"\n",
        "\n",
        "        # Summary\n",
        "        summary = data.get(\"summary\", {})\n",
        "        text += f\"Total Alarms: {summary.get('total_alarms', 'N/A')}, Resolved: {summary.get('resolved_alarms', 'N/A')}, Rate: {summary.get('resolution_rate in Percentage', 'N/A')}\\n\"\n",
        "        time_period = summary.get(\"time_period\", {})\n",
        "        text += f\"Period: {time_period.get('start', 'N/A')[:10]} to {time_period.get('end', 'N/A')[:10]}\\n\"\n",
        "\n",
        "        # Distributions (top items only)\n",
        "        distributions = data.get(\"distributions\", {})\n",
        "        for dist_type in [\"by_client\", \"by_type\", \"by_name\"]:\n",
        "            if dist_type in distributions:\n",
        "                items = sorted(distributions[dist_type].items(), key=lambda x: x[1], reverse=True)[:2]\n",
        "                text += f\"{dist_type.replace('_', ' ').title()}: {items[0][0]} ({items[0][1]}), {items[1][0]} ({items[1][1]})\\n\"\n",
        "\n",
        "        # Top Source\n",
        "        source_analysis = data.get(\"source_analysis\", {})\n",
        "        for source, details in source_analysis.get(\"top_20\", {}).items():\n",
        "            text += f\"Top Source: {source} ({details.get('count', 'N/A')} alarms)\\n\"\n",
        "            break\n",
        "\n",
        "        # Performance\n",
        "        performance = data.get(\"performance\", {})\n",
        "        resolution_times = performance.get(\"resolution_times\", {}).get(\"Door Open\", {})\n",
        "        text += f\"Door Open Resolution: Mean {resolution_times.get('mean', 'N/A')} min\\n\"\n",
        "        sla = performance.get(\"sla_compliance/Resolved within the time limit\", {})\n",
        "        text += f\"SLA: 15min {sla.get('within_15min', 'N/A')}%\\n\"\n",
        "\n",
        "        return text, data\n",
        "    except json.JSONDecodeError:\n",
        "        return f\"Invalid JSON in {filename}.\", {}\n",
        "\n",
        "def preprocess_query(user_query, json_data_list, previous_query=None):\n",
        "    \"\"\"Answer queries directly from JSON data.\"\"\"\n",
        "    user_query = user_query.lower().strip()\n",
        "\n",
        "    # Handle clarifications\n",
        "    if \"not client\" in user_query and previous_query:\n",
        "        if \"type\" in user_query:\n",
        "            user_query = previous_query.replace(\"client\", \"type\")\n",
        "\n",
        "    # Broad queries\n",
        "    if any(phrase in user_query for phrase in [\"details\", \"about alarms\", \"tell me about\", \"overview\"]):\n",
        "        for json_data in json_data_list:\n",
        "            summary = json_data.get(\"summary\", {})\n",
        "            total = summary.get(\"total_alarms\", \"N/A\")\n",
        "            resolved = summary.get(\"resolved_alarms\", \"N/A\")\n",
        "            rate = summary.get(\"resolution_rate in Percentage\", \"N/A\")\n",
        "            by_client = sorted(json_data.get(\"distributions\", {}).get(\"by_client\", {}).items(), key=lambda x: x[1], reverse=True)[:2]\n",
        "            by_type = sorted(json_data.get(\"distributions\", {}).get(\"by_type\", {}).items(), key=lambda x: x[1], reverse=True)[:2]\n",
        "            by_name = sorted(json_data.get(\"distributions\", {}).get(\"by_name\", {}).items(), key=lambda x: x[1], reverse=True)[:1]\n",
        "            source = list(json_data.get(\"source_analysis\", {}).get(\"top_20\", {}).items())[0][0] if json_data.get(\"source_analysis\", {}).get(\"top_20\", {}) else \"N/A\"\n",
        "            source_count = json_data.get(\"source_analysis\", {}).get(\"top_20\", {}).get(source, {}).get(\"count\", \"N/A\") if source != \"N/A\" else \"N/A\"\n",
        "            resolution_times = json_data.get(\"performance\", {}).get(\"resolution_times\", {}).get(\"Door Open\", {})\n",
        "            sla = json_data.get(\"performance\", {}).get(\"sla_compliance/Resolved within the time limit\", {})\n",
        "            return (f\"{total} alarms, {resolved} resolved ({rate}). Top clients: {by_client[0][0]} ({by_client[0][1]}), \"\n",
        "                    f\"{by_client[1][0]} ({by_client[1][1]}). Top types: {by_type[0][0]} ({by_type[0][1]}), {by_type[1][0]} ({by_type[1][1]}). \"\n",
        "                    f\"Top alarm: {by_name[0][0]} ({by_name[0][1]}). Top source: {source} ({source_count} alarms). \"\n",
        "                    f\"Door Open resolution: {resolution_times.get('mean', 'N/A')} min avg. SLA: {sla.get('within_15min', 'N/A')}% in 15 min.\")\n",
        "\n",
        "    # Total alarms\n",
        "    if \"total\" in user_query and \"alarm\" in user_query:\n",
        "        for json_data in json_data_list:\n",
        "            total_alarms = json_data.get(\"summary\", {}).get(\"total_alarms\", \"N/A\")\n",
        "            if total_alarms != \"N/A\":\n",
        "                return f\"The total number of alarms is {total_alarms}.\"\n",
        "\n",
        "    # Resolved alarms\n",
        "    if \"resolved\" in user_query and \"alarm\" in user_query:\n",
        "        for json_data in json_data_list:\n",
        "            resolved_alarms = json_data.get(\"summary\", {}).get(\"resolved_alarms\", \"N/A\")\n",
        "            if resolved_alarms != \"N/A\":\n",
        "                return f\"{resolved_alarms} alarms were resolved.\"\n",
        "\n",
        "    # Resolution rate\n",
        "    if \"resolution rate\" in user_query:\n",
        "        for json_data in json_data_list:\n",
        "            resolution_rate = json_data.get(\"summary\", {}).get(\"resolution_rate in Percentage\", \"N/A\")\n",
        "            if resolution_rate != \"N/A\":\n",
        "                return f\"The resolution rate is {resolution_rate}.\"\n",
        "\n",
        "    # Time period\n",
        "    if any(phrase in user_query for phrase in [\"time period\", \"when\", \"date\"]):\n",
        "        for json_data in json_data_list:\n",
        "            time_period = json_data.get(\"summary\", {}).get(\"time_period\", {})\n",
        "            start = time_period.get(\"start\", \"N/A\")[:10]\n",
        "            end = time_period.get(\"end\", \"N/A\")[:10]\n",
        "            if start != \"N/A\" and end != \"N/A\":\n",
        "                return f\"The alarms were recorded from {start} to {end}.\"\n",
        "\n",
        "    # Daily alarms\n",
        "    if \"day\" in user_query and \"alarm\" in user_query:\n",
        "        for json_data in json_data_list:\n",
        "            total_alarms = json_data.get(\"summary\", {}).get(\"total_alarms\", \"N/A\")\n",
        "            time_period = json_data.get(\"summary\", {}).get(\"time_period\", {})\n",
        "            start = time_period.get(\"start\", \"N/A\")\n",
        "            end = time_period.get(\"end\", \"N/A\")\n",
        "            if total_alarms != \"N/A\" and start != \"N/A\" and end != \"N/A\":\n",
        "                start_date = datetime.strptime(start[:10], \"%Y-%m-%d\")\n",
        "                end_date = datetime.strptime(end[:10], \"%Y-%m-%d\")\n",
        "                days = (end_date - start_date).days + 1\n",
        "                avg_alarms = round(total_alarms / days)\n",
        "                return f\"The data doesn’t give daily breakdowns, but with {total_alarms} alarms over {days} days, that’s about {avg_alarms} alarms per day.\"\n",
        "\n",
        "    # Weekly alarms or frequency\n",
        "    if (\"week\" in user_query or \"frequency\" in user_query) and \"alarm\" in user_query:\n",
        "        for json_data in json_data_list:\n",
        "            total_alarms = json_data.get(\"summary\", {}).get(\"total_alarms\", \"N/A\")\n",
        "            time_period = json_data.get(\"summary\", {}).get(\"time_period\", {})\n",
        "            start = time_period.get(\"start\", \"N/A\")\n",
        "            end = time_period.get(\"end\", \"N/A\")\n",
        "            weekly = json_data.get(\"temporal_trends\", {}).get(\"weekly\", {})\n",
        "            if weekly:\n",
        "                for source, details in weekly.items():\n",
        "                    counts = details.get(\"counts\", {})\n",
        "                    for week, count in counts.items():\n",
        "                        if str(week) in user_query or \"most\" in user_query or \"highest\" in user_query:\n",
        "                            return f\"{source} had {count} alarms in week {week}.\"\n",
        "            if total_alarms != \"N/A\" and start != \"N/A\" and end != \"N/A\":\n",
        "                start_date = datetime.strptime(start[:10], \"%Y-%m-%d\")\n",
        "                end_date = datetime.strptime(end[:10], \"%Y-%m-%d\")\n",
        "                days = (end_date - start_date).days + 1\n",
        "                avg_weekly = round(total_alarms * 7 / days)\n",
        "                return f\"The data doesn’t give full weekly breakdowns, but with {total_alarms} alarms over {days} days, that’s about {avg_weekly} alarms per week.\"\n",
        "\n",
        "    # Alarm type queries\n",
        "    if \"type\" in user_query or any(type_name.lower() in user_query for type_name in [\"freezer\", \"chiller\", \"lv panel meter\", \"commercial tower\", \"thermostat\", \"sub community\"]):\n",
        "        by_type = {}\n",
        "        for json_data in json_data_list:\n",
        "            by_type.update(json_data.get(\"distributions\", {}).get(\"by_type\", {}))\n",
        "\n",
        "        if \"highest\" in user_query or \"most\" in user_query:\n",
        "            max_type = max(by_type, key=by_type.get, default=None)\n",
        "            if max_type:\n",
        "                return f\"The most common alarm type is {max_type} with {by_type[max_type]} alarms.\"\n",
        "        elif \"fewest\" in user_query or \"least\" in user_query:\n",
        "            min_type = min(by_type, key=by_type.get, default=None)\n",
        "            if min_type:\n",
        "                return f\"The least common alarm type is {min_type} with {by_type[min_type]} alarms.\"\n",
        "        else:\n",
        "            for type_name in by_type:\n",
        "                if type_name.lower() in user_query:\n",
        "                    return f\"There were {by_type[type_name]} {type_name} alarms.\"\n",
        "\n",
        "    # Client queries\n",
        "    if \"client\" in user_query or any(client.lower() in user_query for client in [\"ksa\", \"uae\", \"bahrain\"]):\n",
        "        by_client = {}\n",
        "        for json_data in json_data_list:\n",
        "            by_client.update(json_data.get(\"distributions\", {}).get(\"by_client\", {}))\n",
        "\n",
        "        if \"highest\" in user_query or \"most\" in user_query:\n",
        "            max_client = max(by_client, key=by_client.get, default=None)\n",
        "            if max_client:\n",
        "                return f\"The client with the most alarms is {max_client} with {by_client[max_client]} alarms.\"\n",
        "        elif \"fewest\" in user_query or \"least\" in user_query:\n",
        "            min_client = min(by_client, key=by_client.get, default=None)\n",
        "            if min_client:\n",
        "                return f\"The client with the fewest alarms is {min_client} with {by_client[min_client]} alarms.\"\n",
        "        else:\n",
        "            for client in by_client:\n",
        "                if client.lower() in user_query:\n",
        "                    return f\"{client} had {by_client[client]} alarms.\"\n",
        "\n",
        "    # Group queries\n",
        "    if \"group\" in user_query or any(group.lower() in user_query for group in [\"environmental\", \"electrical\", \"preventive\"]):\n",
        "        by_group = {}\n",
        "        for json_data in json_data_list:\n",
        "            by_group.update(json_data.get(\"distributions\", {}).get(\"by_group\", {}))\n",
        "\n",
        "        if \"highest\" in user_query or \"most\" in user_query:\n",
        "            max_group = max(by_group, key=by_group.get, default=None)\n",
        "            if max_group:\n",
        "                return f\"The most common alarm group is {max_group} with {by_group[max_group]} alarms.\"\n",
        "        elif \"fewest\" in user_query or \"least\" in user_query:\n",
        "            min_group = min(by_group, key=by_group.get, default=None)\n",
        "            if min_group:\n",
        "                return f\"The least common alarm group is {min_group} with {by_group[min_group]} alarms.\"\n",
        "        else:\n",
        "            for group in by_group:\n",
        "                if group.lower() in user_query:\n",
        "                    return f\"There were {by_group[group]} {group} alarms.\"\n",
        "\n",
        "    # Alarm name queries\n",
        "    if \"name\" in user_query or any(name.lower() in user_query for name in [\"door open\", \"extremely high temperature\", \"high temperature\", \"low temperature\", \"no power\", \"site not communicating\"]):\n",
        "        by_name = {}\n",
        "        for json_data in json_data_list:\n",
        "            by_name.update(json_data.get(\"distributions\", {}).get(\"by_name\", {}))\n",
        "\n",
        "        if \"highest\" in user_query or \"most\" in user_query:\n",
        "            max_name = max(by_name, key=by_name.get, default=None)\n",
        "            if max_name:\n",
        "                return f\"The most common alarm name is {max_name} with {by_name[max_name]} alarms.\"\n",
        "        elif \"fewest\" in user_query or \"least\" in user_query:\n",
        "            min_name = min(by_name, key=by_name.get, default=None)\n",
        "            if min_name:\n",
        "                return f\"The least common alarm name is {min_name} with {by_name[min_name]} alarms.\"\n",
        "        else:\n",
        "            for name in by_name:\n",
        "                if name.lower() in user_query:\n",
        "                    return f\"There were {by_name[name]} {name} alarms.\"\n",
        "\n",
        "    # Source queries\n",
        "    if \"source\" in user_query or \"t 118709 ch 02\" in user_query:\n",
        "        for json_data in json_data_list:\n",
        "            top_20 = json_data.get(\"source_analysis\", {}).get(\"top_20\", {})\n",
        "            for source, details in top_20.items():\n",
        "                if source.lower() in user_query or \"most\" in user_query or \"highest\" in user_query:\n",
        "                    return f\"{source} at {details.get('path', 'N/A')} had {details.get('count', 'N/A')} alarms.\"\n",
        "\n",
        "    # Resolution time queries\n",
        "    if \"resolution time\" in user_query and \"door open\" in user_query:\n",
        "        for json_data in json_data_list:\n",
        "            resolution_times = json_data.get(\"performance\", {}).get(\"resolution_times\", {}).get(\"Door Open\", {})\n",
        "            mean = resolution_times.get(\"mean\", \"N/A\")\n",
        "            median = resolution_times.get(\"median\", \"N/A\")\n",
        "            if mean != \"N/A\":\n",
        "                return f\"Door Open alarms have an average resolution time of {mean} minutes and a median of {median} minutes.\"\n",
        "\n",
        "    # SLA compliance queries\n",
        "    if \"sla\" in user_query or \"within\" in user_query:\n",
        "        for json_data in json_data_list:\n",
        "            sla = json_data.get(\"performance\", {}).get(\"sla_compliance/Resolved within the time limit\", {})\n",
        "            if \"15\" in user_query:\n",
        "                return f\"{sla.get('within_15min', 'N/A')}% of alarms were resolved within 15 minutes.\"\n",
        "            if \"30\" in user_query:\n",
        "                return f\"{sla.get('within_30min', 'N/A')}% of alarms were resolved within 30 minutes.\"\n",
        "            if \"1 hour\" in user_query or \"1hr\" in user_query:\n",
        "                return f\"{sla.get('within_1hour', 'N/A')}% of alarms were resolved within 1 hour.\"\n",
        "\n",
        "    # Comparative queries\n",
        "    if any(word in user_query for word in [\"more\", \"less\", \"compare\", \"than\"]):\n",
        "        by_type = {}\n",
        "        by_client = {}\n",
        "        by_name = {}\n",
        "        for json_data in json_data_list:\n",
        "            by_type.update(json_data.get(\"distributions\", {}).get(\"by_type\", {}))\n",
        "            by_client.update(json_data.get(\"distributions\", {}).get(\"by_client\", {}))\n",
        "            by_name.update(json_data.get(\"distributions\", {}).get(\"by_name\", {}))\n",
        "\n",
        "        for item1 in by_type:\n",
        "            for item2 in by_type:\n",
        "                if item1.lower() in user_query and item2.lower() in user_query and item1 != item2:\n",
        "                    count1, count2 = by_type[item1], by_type[item2]\n",
        "                    return f\"{item1} had {count1} alarms, {'more' if count1 > count2 else 'fewer'} than {item2} with {count2} alarms.\"\n",
        "\n",
        "        for item1 in by_client:\n",
        "            for item2 in by_client:\n",
        "                if item1.lower() in user_query and item2.lower() in user_query and item1 != item2:\n",
        "                    count1, count2 = by_client[item1], by_client[item2]\n",
        "                    return f\"{item1} had {count1} alarms, {'more' if count1 > count2 else 'fewer'} than {item2} with {count2} alarms.\"\n",
        "\n",
        "        for item1 in by_name:\n",
        "            for item2 in by_name:\n",
        "                if item1.lower() in user_query and item2.lower() in user_query and item1 != item2:\n",
        "                    count1, count2 = by_name[item1], by_name[item2]\n",
        "                    return f\"{item1} had {count1} alarms, {'more' if count1 > count2 else 'fewer'} than {item2} with {count2} alarms.\"\n",
        "\n",
        "    # Hourly data\n",
        "    if \"hour\" in user_query:\n",
        "        return \"Sorry, the data doesn't include hourly alarm breakdowns. Try asking about weekly trends or other data.\"\n",
        "\n",
        "    # Ambiguous queries\n",
        "    if \"not\" in user_query and not previous_query:\n",
        "        return \"Can you clarify what you mean? For example, are you asking about alarm types or names?\"\n",
        "\n",
        "    return None\n",
        "\n",
        "def generate_response(user_query, context, json_data_list, previous_query=None):\n",
        "    \"\"\"Generate a concise response.\"\"\"\n",
        "    direct_answer = preprocess_query(user_query, json_data_list, previous_query)\n",
        "    if direct_answer:\n",
        "        return direct_answer\n",
        "\n",
        "    try:\n",
        "        generator = pipeline('text-generation', model='distilgpt2')\n",
        "        prompt = f\"Answer concisely using only this data. Do not invent numbers or details:\\n{context}\\nQuery: {user_query}\\nAnswer:\"\n",
        "        response = generator(prompt, max_new_tokens=30, num_return_sequences=1, truncation=True)\n",
        "        answer = response[0]['generated_text'].split(\"Answer:\")[1].strip()\n",
        "        if not answer or any(word in answer.lower() for word in [\"unknown\", \"no data\"]):\n",
        "            return \"Sorry, I couldn't find an answer. Can you be more specific?\"\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        return f\"Sorry, I couldn't find an answer. Can you be more specific?\"\n",
        "\n",
        "def main():\n",
        "    print(\"Upload JSON files or use sample data.\")\n",
        "    use_sample = input(\"Use sample JSON? (y/n): \").lower() == 'y'\n",
        "\n",
        "    contexts = []\n",
        "    json_data_list = []\n",
        "    previous_query = None\n",
        "\n",
        "    if use_sample:\n",
        "        context, json_data = parse_json_to_text(sample_json, \"sample.json\")\n",
        "        contexts.append(context)\n",
        "        json_data_list.append(json_data)\n",
        "    else:\n",
        "        uploaded = files.upload()\n",
        "        if not uploaded:\n",
        "            print(\"No files uploaded. Using sample JSON.\")\n",
        "            context, json_data = parse_json_to_text(sample_json, \"sample.json\")\n",
        "            contexts.append(context)\n",
        "            json_data_list.append(json_data)\n",
        "        else:\n",
        "            for filename, content in uploaded.items():\n",
        "                json_data = content.decode('utf-8')\n",
        "                context, parsed_data = parse_json_to_text(json_data, filename)\n",
        "                contexts.append(context)\n",
        "                json_data_list.append(parsed_data)\n",
        "\n",
        "    print(\"\\nData loaded. Ask away!\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"Ask a question (or type 'exit' to quit): \")\n",
        "        if user_query.lower() == 'exit':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = generate_response(user_query, \"\\n\".join(contexts), json_data_list, previous_query)\n",
        "        print(f\"Answer: {response}\")\n",
        "        previous_query = user_query\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "UQCJmSIZbHni",
        "outputId": "71dffedd-503b-49e2-f7e8-a642fcbf271a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload JSON files or use sample data.\n",
            "Use sample JSON? (y/n): n\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f5a1c50d-2973-4b47-bf88-3693a77dfd6c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f5a1c50d-2973-4b47-bf88-3693a77dfd6c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving alarm_analysis_results (20).json to alarm_analysis_results (20) (8).json\n",
            "\n",
            "Data loaded. Ask away!\n",
            "Ask a question (or type 'exit' to quit): frequency of alarms\n",
            "Answer: The data doesn’t give full weekly breakdowns, but with 10380 alarms over 12 days, that’s about 6055 alarms per week.\n",
            "Ask a question (or type 'exit' to quit): which is least alarm count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: A number of times the first alarm should be detected\n",
            "A number of times the first alarm should be detected\n",
            "A number of times the first alarm should\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d22964a04b51>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-d22964a04b51>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ask a question (or type 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}